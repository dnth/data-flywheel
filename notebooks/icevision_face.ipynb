{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gdown --fuzzy 'https://drive.google.com/file/d/1mqtONldpayaQ97SH1p_UfdoH6nywVfYt/view?usp=sharing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('detection_results_validation.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['classid'] == 0] # only get rows with class 0 person.\n",
    "df.loc[df['classid'] == 0, 'classid'] = 'person'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Data to VOC format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "def create_voc_xml(filename, objects, output_dir):\n",
    "    # Create the root element\n",
    "    annotation = ET.Element('annotation')\n",
    "\n",
    "    # Add the filename element\n",
    "    filename_elem = ET.SubElement(annotation, 'filename')\n",
    "    filename_elem.text = os.path.basename(filename)\n",
    "\n",
    "    # Add the size element (assuming a fixed size, you can modify this according to your needs)\n",
    "    size = ET.SubElement(annotation, 'size')\n",
    "    width = ET.SubElement(size, 'width')\n",
    "    width.text = '1024'  # Replace with the actual width of your image\n",
    "    height = ET.SubElement(size, 'height')\n",
    "    height.text = '1024'  # Replace with the actual height of your image\n",
    "    depth = ET.SubElement(size, 'depth')\n",
    "    depth.text = '3'\n",
    "\n",
    "    # Add the object elements\n",
    "    for obj in objects:\n",
    "        obj_elem = ET.SubElement(annotation, 'object')\n",
    "        name = ET.SubElement(obj_elem, 'name')\n",
    "        name.text = str(obj['classid'])\n",
    "        pose = ET.SubElement(obj_elem, 'pose')\n",
    "        pose.text = 'Unspecified'\n",
    "        truncated = ET.SubElement(obj_elem, 'truncated')\n",
    "        truncated.text = '0'\n",
    "        difficult = ET.SubElement(obj_elem, 'difficult')\n",
    "        difficult.text = '0'\n",
    "        bndbox = ET.SubElement(obj_elem, 'bndbox')\n",
    "        xmin = ET.SubElement(bndbox, 'xmin')\n",
    "        xmin.text = str(obj['x1'])\n",
    "        ymin = ET.SubElement(bndbox, 'ymin')\n",
    "        ymin.text = str(obj['y1'])\n",
    "        xmax = ET.SubElement(bndbox, 'xmax')\n",
    "        xmax.text = str(obj['x2'])\n",
    "        ymax = ET.SubElement(bndbox, 'ymax')\n",
    "        ymax.text = str(obj['y2'])\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Generate the output file path\n",
    "    output_file = os.path.join(output_dir, os.path.splitext(os.path.basename(filename))[0] + '.xml')\n",
    "\n",
    "    # Write the XML to the output file\n",
    "    tree = ET.ElementTree(annotation)\n",
    "    tree.write(output_file, encoding='utf-8', xml_declaration=True)\n",
    "\n",
    "\n",
    "output_directory = 'pascal_voc_annotations'\n",
    "\n",
    "grouped_df = df.groupby('filename').apply(lambda x: x.to_dict('records')).reset_index(name='objects')\n",
    "\n",
    "for _, row in grouped_df.iterrows():\n",
    "    filename = row['filename']\n",
    "    objects = row['objects']\n",
    "    create_voc_xml(filename, objects, output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot XML to verify conversion is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_image_with_bounding_boxes(xml_path, image_folder):\n",
    "    # Parse the XML file\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Get the image filename from the XML\n",
    "    image_filename = root.find('filename').text\n",
    "    image_path = os.path.join(image_folder, image_filename)\n",
    "\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Extract the bounding box information\n",
    "    for obj in root.findall('object'):\n",
    "        bndbox = obj.find('bndbox')\n",
    "        xmin = int(bndbox.find('xmin').text)\n",
    "        ymin = int(bndbox.find('ymin').text)\n",
    "        xmax = int(bndbox.find('xmax').text)\n",
    "        ymax = int(bndbox.find('ymax').text)\n",
    "        class_id = obj.find('name').text\n",
    "\n",
    "        # Draw the bounding box on the image\n",
    "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "\n",
    "        # Put the class ID text above the bounding box\n",
    "        cv2.putText(image, class_id, (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the image with bounding boxes and class IDs\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = '/workspace/yolo_v8_training/oiv7_full/validation/'\n",
    "xml_path = 'pascal_voc_annotations/011417767312812e.xml'\n",
    "plot_image_with_bounding_boxes(xml_path, image_folder)\n",
    "\n",
    "# {0: 'person', 1: 'head', 2: 'hand', 3: 'face'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Into IceVision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icevision.all import *\n",
    "\n",
    "parser = parsers.VOCBBoxParser(annotations_dir='pascal_voc_annotations/', \n",
    "                               images_dir='/workspace/yolo_v8_training/oiv7_full/validation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse annotations to create records\n",
    "train_records, valid_records = parser.parse() # Defaults to 80:20 split\n",
    "parser.class_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 384\n",
    "train_tfms = tfms.A.Adapter([*tfms.A.aug_tfms(size=image_size, presize=512), tfms.A.Normalize()])\n",
    "valid_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(image_size), tfms.A.Normalize()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(train_records, train_tfms)\n",
    "valid_ds = Dataset(valid_records, valid_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Show an element of the train_ds with augmentation transformations applied\n",
    "samples = [train_ds[0] for _ in range(3)]\n",
    "show_samples(samples, ncols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_args = {}\n",
    "\n",
    "model_type = models.ultralytics.yolov5\n",
    "backbone = model_type.backbones.small\n",
    "extra_args['img_size'] = image_size\n",
    "\n",
    "model = model_type.model(backbone=backbone(pretrained=True), num_classes=len(parser.class_map), **extra_args) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loaders\n",
    "train_dl = model_type.train_dl(train_ds, batch_size=8, num_workers=4, shuffle=True)\n",
    "valid_dl = model_type.valid_dl(valid_ds, batch_size=8, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show batch\n",
    "model_type.show_batch(first(valid_dl), ncols=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [COCOMetric(metric_type=COCOMetricType.bbox)]\n",
    "\n",
    "learn = model_type.fastai.learner(dls=[train_dl, valid_dl], model=model, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(20, 0.001, freeze_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type.show_results(model, valid_ds, detection_threshold=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_samples, sorted_preds, losses_stats = model_type.interp.plot_top_losses(model, valid_ds, sort_by=\"loss_total\", n_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icevision.models.checkpoint import *\n",
    "save_icevision_checkpoint(model,\n",
    "                        model_name='ultralytics.yolov5', \n",
    "                        backbone_name='small',\n",
    "                        img_size=384,\n",
    "                        classes=parser.class_map.get_classes(),\n",
    "                        filename='./models/model_checkpoint.pth',\n",
    "                        meta={'icevision_version': '0.12.0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
